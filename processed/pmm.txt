CUDA is available.
 it up into recommendations for all of our dear friends on the content marketing sales and product teams um voices happens twice a year and kind of normally at about six months uh but we time it carefully to ensure that you all have the latest and greatest as you head into your planning cycles so uh this is basically covering the h2 planning cycle um today what we'll do is we'll go over the last six-ish months of insights. And these are insights that have been synthesized across the larger team. So with many thanks to our market research, market intelligence, product champs, couple of voices, field teams, B365, the artist formerly known as AHA, solutions engineering, and our own PMM team. Just lots of thanks to all of the teams represented here. And huge thanks to Roger Lamb who helped us coalesce and get all of these insights into one place. So lots and lots of insights here. And, oh, sorry. Is that one of a question? Maybe not. Okay. We boiled these down and we will be delivering a set of clear recommendations, which I've stack ranked with help from our biz ops friends based on commercial impact. And our goal here is to get you to a top list. It's a rough top 10 or so of what we recommend building in H2 and beyond to help us realize our mission as a company and drive revenue and impact in the market. So without further ado, I'm going to dive in. We have about 30 minutes today. It'll be fast and furious. I'm going to go over the top line and then we'll queue it up for questions. We have our experts here on the call from across our Insights and PMM teams. So go ahead and pop your questions into the chat and they'll be helping to answer questions both in the chat and then we'll save most of the call actually for questions at the end. Let me think. Is there anything else that we need? Oh, yeah. One last thing. This document, we're going to go over the top section here, but not to make you guys dizzy, but it's a 40 page document. So the way that it's structured is the top is the executive summary and specifically the P0. So that's what we feel like we should be building specifically in H2. There's also a list of insights and recommendations for beyond H2. So we have our P1s and P2s, which are more looking forward to FY26. and then below this you'll find another 30 plus pages of market intel sales insights and track level insights for each of the core product areas so for my product friends on the call i really want to encourage you to look deeply into your specific like track level insights reach out for each of these areas you can see who the lead is so for example for market trends our lead is Hannah Lesk. If you have a question about this, feel free to reach out to Hannah to comment in this doc. This is the living, breathing source of truth document. And we hope to use it to help answer your questions. So please feel free to comment liberally, to reach out to us. The goal is to leave no question unanswered. Okay. So with that, I'm going to dive in and we'll take questions at the end. So I want to start by talking a little bit about our top product and content recommendations. And then we'll go over marketing recommendations in a moment here. So these are recommendations for things that I want to strongly advise that we build in each too. So these are areas where we feel like we've sufficiently scoped these, we've seen them consistently, and we feel like these are the top ways to drive revenue for the company. The first is around building foundations for skills proficiency reporting. And this has really been a top request from customers and something that we see as a growing area of opportunity and even I would say an area where if we don't invest here, we may be losing our edge. there's a couple p zeros that we want to recommend funding or i would say continuing to fund and you'll notice here some of these have already been funded or they're partially funded so a lot of these are a keep doing not so much a start doing for the ones that are not yet funded i want to recommend to our product friends that they consider funding these as their top priority areas so the The first is working together across product content, and I would say probably PMM as well, to define the model for how we measure skill proficiency. The second is developing foundational skill proficiency signals to unblock reporting. And I linked here, there's kind of a list of different signals that we can use. And our recommendation is to invest in those that have the highest credibility, but the lowest cost to build. So for example, you know, exams, quizzes, or net new engagement based signals. There's a lot of additional information about this particular topic. And we're going to be hosting a follow up with product tomorrow morning. So we can take questions either on this call at the end or also in that meeting tomorrow. And you'll see there's also a lot of additional information that's linked out for this one. So another piece here in this area is to begin to build the reporting interfaces that actually provide our customers with a way to view those metrics. So the first piece is kind of defining what the metric is. The second is building those signals. And then the third is around like taking those signals and putting it into an interface that allows our admins an easy way to view those metrics and to gauge the impact of their learning programs on their ROI. And again, the reason that this is really important is because we know that having a clear way to prove ROI for admins is going to be one of the main drivers for improving renewals and addressing churn. A couple other kind of specific details here, which I'm going to gloss over in the interest of time, but lots of additional detail here. um so that's again skills proficiency reporting building out these kind of foundational pieces um that is the top recommendation our second recommendation and again these are stack ranked um is to close gaps in our core career development capabilities um and i want to just be really clear this is kind of some of the foundational things that and a lot of these are partially funded already or funded um where we feel like this is kind of essential for for getting just like the base capabilities, right, for career development. So the first is making sure that org customization and internal jobs flow through all of our career development features. And I think this is, you know, partially funded. It's also dependent on the career skew dependency. And then also making sure that we add skill proficiencies and skill assessments to our learning plans. That's something that I think we should consider funding. It's not yet funded. There's a marketing, a couple marketing suggestions in here about driving career development features through admin playbooks and also surfacing internal jobs in hub and properly routing applicants by getting the key ATS partners to adopt the IAM integrations. And then finally, tracking and exposing aggregate and interested candidates opt in liquidity. And so I think across looking across all of these, again, these are both stack ranked within the larger super headings and then within those categories. What I would say is it looks like there's some here that are partially funded, but we should be looking carefully at these ones that are highlighted in red and asking if there's a way to build towards these in each two. um the third area is something that i know that we've talked about in the past and i think that we're highlighting it as an area of opportunity again certainly number three but definitely important is delivering on strategic integrations um so there's two pieces of this the first is improving outbound integrations and then the second is around prioritization of hcm platform integrations. So there's some more detail here about high level improving integrations. And I think this is a combination of product and actually like BD recommendations for how we want to deliver on this. And then finally, our last, but certainly not least, P0 is to continue to invest in our content, specifically to stay at par with AI content by focusing on hands-on practice features, format reporting for content, and improved merchandising, both in and off product. Making sure that we're continuing to develop and push out our fresh AI content, and really focusing on how we can take our current AI upskilling solution and make it enterprise grade. A couple specific recommendations here, which I'll kind of gloss over in the specific or in the needs of for time. But this one is one that's interesting. It's really a specific mix of content, product, and marketing. So getting AI content right and really delivering on an enterprise-grade solution for AI upskilling is going to take a village. It's going to be a team effort. I did want to highlight one last recommendation here. The P1s that we have here are mainly recommended to scope in H2. It's areas where we need to do a little bit more work and investment across our teams. But there is one where we feel like there's pieces of it that can be built in H2, kind of starting in H2 and then building through FY26. and that's around Gen AI. So I think in the past, a lot of times our Gen AI conversations have focused on Gen AI as a what. And I think our recommendation is really more to focus on Gen AI as a how in H2 in terms of how Gen AI helps us to deliver solutions on the top areas above. So specifically, I think this looks at how do we use Gen AI to drive skill proficiency, reporting, career development? So we have a couple P0s there. So this is kind of confusing because it's a P0 within a P1, but what we're saying is kind of overall we're scoping for Gen AI in H2. But specifically, we want to encourage focus on areas where we continue to make our AI features more enterprise grade. And there's a couple specific recommendations there around accessibility and coach reporting, as well as recommendations around custom content and custom talent architecture. And then the second piece of this, which the team is, I know, already leaning into is scoping and starting to investigate how we might build agents to solve for some of our top customer pain points and drive additional value there. There's three kind of sub areas. The first is skills-based insights and recommendations. The second is on automating the admin reporting experience. And the third is on offering conversation-based career guidance for learners, specifically more guidance than career exploration and adapting that to in real time to the learner's progress. And there's a couple others here. The last one I'll just say is making Gen.ai more insightful for admins with AI assisted insights and skill-based insights. This is areas we're already, I think, leaning into. So this is a keep doing, keep going. There's so much more, guys. I could go on forever and ever, but I know we probably have questions in the chat. Also, marketing friends on the call, I will just bring your attention to that there are, these are our top marketing recommendations here, but you'll see marketing recommendations kind of throughout as well as content. This is primarily a product focused readout, but there definitely are marketing content recommendations listed throughout. So with that, I'm actually going to stop sharing my teensy tiny screen and look back at all of your wonderful faces and see if we have any questions in the chat. Feel free to raise your hands. We have a lot of folks on the call so I'll do my best to to go and uh to reach everybody but maybe starting with Will do you want to voice over your question on skill proficiency uh sure so I think skill proficiency in the discussions we've had means a lot of different things to a lot of different people and folks would measure it very differently depending on how we would tackle it uh so I think my questions are around is there any more granular kind of guidance are they expecting a really complex bunches of inputs all aggregate somehow into some top line roll-up score or is this more of like a few simpler inputs could get us there and then kind of in parallel who expects that um if bigger lent gcp folks are all in lms do they expect this to be in that lms or is this really more of like a mid-market, smaller enterprise, P0-esque. Such great questions. I know Crew and Brendan are on the call. I'm going to pass it to Crew, but I will just say briefly that I think the perfect's the enemy of the good here. I don't actually think that what we need to build is hugely complex. We're already really differentiated in terms of people, how people look to us for our data. They trust our data insights. But Crew can say more on this than I can. Crew, do you want to respond? Yeah. Yeah. Just hopping in here, I think some myths that we busted last half as we were going into planning was, to Sarai's point, if we think about the credibility scale, there's on one end, the least credible in terms of self-reporter inferred. So pulling from, let's say, skills from profile. And the other end, super, super, super, super credible, but probably unattainable for thinking about a multimodal approach. And what we found was that the sweet spot here, the combination and how we go about it, there's a couple options you put in, is a combination of engagement signals, assessment signals. that could either be one score or as simple as just showing, hey, transparently, these are all the signals that we're using to validate skills. And then as a double click, what proficiency looks like through assessments, for instance. So I think it's, to answer your question of like, what that looks like, it's not this, customers aren't looking for this super, super advanced, you know, point of view here because we have nothing. right now. And something that's better than nothing is the sweet spot of combining engagement signals, looking at assessments, and then balancing that with what do we have enough liquidity around. And I think this covers the majority of admins across, you know, it's not specific to like one audience. I think we've heard it across the board. A lot of people on this call too have heard it across these different audience segments. So I'll say that, Brennan, don't know if you wanted to hop in there any of our like market intel folks too um yeah i think if we look at that spectrum it's this middle ground oh no i think i think you covered it crew i will just uh reiterate uh this something is better than nothing um drum um because i think like we've just been in the nothing world for for too long and so something is better than nothing um and then will i think for you in terms of how we're thinking through like robustness and sizing and cost and everything there's kind of this ratio of like super credible and low cost to build right and so if something's super credible and low cost to build let's do it if something is um really low credibility but also really low cost to build like maybe that's worth building into the model and prioritizing i think we need to think about this less in terms of like a stack ranking we need to go in a particular order for these things and more of you know something is better than nothing and let's kind of just play that ratio of like highest credibility for lowest cost to build. And Crew's got a lot of more detail on that that we probably don't have time for in terms of like what are all those things in the spectrum of credibility that we can consider. Well, does that kind of answer your question? Awesome. Okay. Do folks have other questions about these top stack ranked areas, how we got to them questions about steve's cat we're here for all of it yeah that summary is so hilarious i uh thank you for sharing that um uh the only thing uh one i know there's a separate meeting on skill proficiency that we have set up the team has my questions um i'm just at a stage of like i think the details really matter at this point like literally how you wanted to find proficiency and then like we just make a call like i think that matters versus like to will's point it's so we'll solve that in a separate meeting i know the team has my questions if there's follow-ups there that i can help with um please let me know what i would like to do for and this is for the pms i hope all on the call i know we do have some um out uh this week too so maybe sir i'll work with you to send a follow-up but when we go through h2 planning i would like us to explicitly call out uh the gaps to this these insights like we should just own it like this is a very good source of truth we're not going to be able to do all of it but let's like have awareness of where we're not doing something and a reason and then i think that just helps us balance versus this kind of being like a suggestion and then we lose kind of that triangulation but just like having um and maybe say if she's on as well or i can follow we get i can work with you but just having that like cross reference point. I think that's where it's just hard for me a little bit sometimes to manage in my head of like, is that on the roadmap? Because a lot of this is like 80% of this looks like it's going to land on our H2 roadmap. But just making sure we're not losing the thread on the things that aren't and owning the things that aren't like maybe skill proficiency. I don't know. I'm making something up doesn't fall on our cut line. But like, let's have a joint answer across this team that everyone understands of like, why isn't it on the list? and not just kind of like leave things in limbo. So just maybe one action item as we are embarking into H2 planning. I think the email is going out like today to start the gong on that. So that would be my one ask that I will follow up on. But this is great. Thank you, Jo. I super appreciate that. And I'll share too, like we really appreciate that on behalf of like the larger team as well. And I know like the sales team, A lot of times these insights kind of get shared and the question is like, where are they going? Where are these customer requests going? Did we fund this? Didn't we fund it? So I'd love to partner with you on kind of having a readout of, you know, yeah, like just closing the loop. So I think that'll be really helpful. I can think of some ways that we can do it pretty easily too. So I'll follow up with you on that. And then I will say too, on the skill proficiency piece, it's interesting. This is actually one of the first times that I've had a recommendation, like that first key zero for skill proficiency is kind of to figure out how we define that metric, right? And to figure out like, what is good enough? And what can we do as LinkedIn that helps position us competitively? And is that balance, Brendan, I think, said it really well, it's that balance of kind of like low cost to build, highest credibility, like simplified as the most bang for our buck. And that is actually something that's like across content product and marketing together and it's really it's interesting it's like one of the first times that i've had a recommendation that was so cross-functional um so it'll be it'll be really interesting to see kind of what comes out from that and i'm looking forward to talking more about that tomorrow um so folks we will send out this entire deck it is huge i think it's 40 some pages um And but the top line is, you know, concise. And I think that, you know, we'll have some follow ups coming from Jill and others out of this. I also want to just encourage folks to bookmark this document because the PMM team maintains this as our source of truth throughout the next six months, which means when we get new studies from our friends on market intelligence, market research, we update this document. And so you can go to it as a source of truth for insights if you're looking for the latest and greatest on something. You can also just ask all the friendly people on this call or who are listed in the document if you have a question. We are here to help. So thank you. With that, I think if there's no other questions, I can give back some time. Anybody else? Will? Will? Hi. I had a question about AI practice on content. Are there folks who are doing this well? Were there specific functionalities or approaches that customers were asking for here? Because AI is actually a really kind of deep set of subjects and subscales and things that you could practice. There's prompt engineering and design and, you know, model selection and model tuning. Like, there's a whole lot of different things where the practice might look very differently. And so I was just curious if there's any more detail there. On the non-tech side, it was pretty just like, if we're going to tell everyone to be productive and that they can be with AI, how can they actually practice prompting? Because they're not familiar with how do I, even with our own tools, like how do they ask the right prompt to get the right productivity things out. And that includes tools-based practice, although I don't know that we would do specific tools-based practice. And then on the tech side, the biggest thing we heard was AI sandboxes, but we would need to dig into like what kind of sandboxes for what. I've heard that on the developer side, and we may have some headway there with GitHub releasing their LLM playground inside of Codespaces, so that may be coming. they announced that at GitHub Universe, but I think there's probably other pieces there. And then there's another key piece here in that we kind of can't let IT Labs and Cyber go because ITDMs are influencing AI tool adoption and therefore influencing upskilling as well. So we're kind of having, if we want to convince ITDMs that we have the AI upskilling they need for the entire org and we want to lead the AI marketing content, we've got to play that, we've got to be able to convince ITDMs with, you know, cyber cloud and AI, especially as cyber takes a bigger chunk of the AI infrastructure. So there's hands-on practice in kind of multiple ways that fall under that AI hands-on practice box. And that's an area where I know we have been really making great inroads over time. And so this is definitely like, I keep up the great work pushing that forward.
